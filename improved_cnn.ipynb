{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68d15ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Load the data\n",
    "digits = np.load('unlabelled_train_data_images.npy')\n",
    "X = digits.reshape(digits.shape[0], -1) / 255.0  # Flatten and normalize\n",
    "\n",
    "# 1. Create a more powerful CNN feature extractor (using transfer learning concepts)\n",
    "def create_deep_cnn_embeddings(X, encoding_dim=64):\n",
    "    \"\"\"\n",
    "    Create embeddings using a deeper CNN with residual connections\n",
    "    \"\"\"\n",
    "    # Reshape for CNN\n",
    "    input_shape = (28, 28, 1)\n",
    "    X_reshaped = X.reshape(-1, 28, 28, 1)\n",
    "    \n",
    "    # Input layer\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # First convolutional block\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    \n",
    "    # Second convolutional block\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    \n",
    "    # Feature extraction\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    encoded = layers.Dense(encoding_dim, activation='relu')(x)\n",
    "    \n",
    "    # Create model\n",
    "    feature_extractor = models.Model(inputs=inputs, outputs=encoded)\n",
    "    \n",
    "    # Create a simple autencoder (optional - for pretraining)\n",
    "    decoded = layers.Dense(784, activation='sigmoid')(encoded)\n",
    "    autoencoder = models.Model(inputs=inputs, outputs=decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    \n",
    "    # Pretrain the autoencoder to get better feature representations\n",
    "    print(\"Pretraining feature extractor using autoencoder...\")\n",
    "    autoencoder.fit(X_reshaped, X, \n",
    "                   epochs=5, \n",
    "                   batch_size=256,\n",
    "                   shuffle=True,\n",
    "                   validation_split=0.1,\n",
    "                   verbose=1)\n",
    "    \n",
    "    # Get embeddings using the encoder part\n",
    "    embeddings = feature_extractor.predict(X_reshaped)\n",
    "    print(f\"CNN embedding shape: {embeddings.shape}\")\n",
    "    \n",
    "    return embeddings, feature_extractor\n",
    "\n",
    "# 2. Improved clustering with hyperparameter tuning and stability checking\n",
    "def improved_clustering(embeddings, min_clusters=8, max_clusters=12):\n",
    "    \"\"\"\n",
    "    Find the optimal number of clusters and perform stabilized clustering\n",
    "    \"\"\"\n",
    "    # Try different numbers of clusters and evaluate using silhouette score\n",
    "    scores = []\n",
    "    models = []\n",
    "    \n",
    "    print(\"Finding optimal number of clusters...\")\n",
    "    for n_clusters in range(min_clusters, max_clusters + 1):\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "        labels = kmeans.fit_predict(embeddings)\n",
    "        score = silhouette_score(embeddings, labels)\n",
    "        scores.append(score)\n",
    "        models.append(kmeans)\n",
    "        print(f\"  {n_clusters} clusters: silhouette score = {score:.4f}\")\n",
    "    \n",
    "    # Choose optimal number of clusters\n",
    "    best_idx = np.argmax(scores)\n",
    "    best_n_clusters = min_clusters + best_idx\n",
    "    best_model = models[best_idx]\n",
    "    \n",
    "    print(f\"Optimal number of clusters: {best_n_clusters} (score: {scores[best_idx]:.4f})\")\n",
    "    \n",
    "    # Perform multiple clusterings and ensemble the results for stability\n",
    "    print(\"Performing ensemble clustering for stability...\")\n",
    "    ensemble_models = []\n",
    "    ensemble_labels = []\n",
    "    \n",
    "    # Create 5 clusterings with different random states\n",
    "    for i in range(5):\n",
    "        kmeans = KMeans(n_clusters=best_n_clusters, random_state=i*10, n_init=10)\n",
    "        labels = kmeans.fit_predict(embeddings)\n",
    "        ensemble_models.append(kmeans)\n",
    "        ensemble_labels.append(labels)\n",
    "    \n",
    "    # Create a consensus clustering by selecting the most common label\n",
    "    # Note: This requires solving the label correspondence problem which is complex\n",
    "    # For simplicity, we'll use the best single clustering instead\n",
    "    labels = best_model.fit_predict(embeddings)\n",
    "    \n",
    "    return labels, best_model, best_n_clusters\n",
    "\n",
    "# 3. Visualize results with better dimensionality reduction\n",
    "def visualize_clusters(embeddings, labels, n_clusters):\n",
    "    \"\"\"\n",
    "    Visualize clusters with improved t-SNE and evaluate cluster quality\n",
    "    \"\"\"\n",
    "    # Use PCA first to reduce dimensionality before t-SNE (better results)\n",
    "    if embeddings.shape[1] > 50:\n",
    "        print(\"Reducing dimensions with PCA before t-SNE...\")\n",
    "        pca = PCA(n_components=50)\n",
    "        embeddings_reduced = pca.fit_transform(embeddings)\n",
    "    else:\n",
    "        embeddings_reduced = embeddings\n",
    "    \n",
    "    # Use t-SNE with better parameters\n",
    "    print(\"Running t-SNE for visualization...\")\n",
    "    tsne = TSNE(n_components=2, \n",
    "                perplexity=50, \n",
    "                learning_rate='auto',\n",
    "                n_iter=1000, \n",
    "                random_state=42)\n",
    "    embeddings_2d = tsne.fit_transform(embeddings_reduced)\n",
    "    \n",
    "    # Plot results with improved visuals\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], \n",
    "                          c=labels, cmap='tab10', alpha=0.7, s=5)\n",
    "    plt.colorbar(scatter)\n",
    "    plt.title('t-SNE visualization of digit clusters', fontsize=15)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot representative samples from each cluster\n",
    "    plot_cluster_examples(digits, labels, n_clusters)\n",
    "    \n",
    "    return embeddings_2d\n",
    "\n",
    "# 4. Plot examples from each cluster with better organization\n",
    "def plot_cluster_examples(images, labels, n_clusters, samples_per_cluster=10):\n",
    "    \"\"\"\n",
    "    Display samples from each cluster in an organized grid\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(samples_per_cluster * 1.2, n_clusters * 1.2))\n",
    "    \n",
    "    # For each cluster\n",
    "    for cluster_id in range(n_clusters):\n",
    "        # Get indices of images in this cluster\n",
    "        cluster_indices = np.where(labels == cluster_id)[0]\n",
    "        \n",
    "        # Skip if cluster is empty\n",
    "        if len(cluster_indices) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Take a sample of images from this cluster\n",
    "        sample_size = min(samples_per_cluster, len(cluster_indices))\n",
    "        sample_indices = np.random.choice(cluster_indices, sample_size, replace=False)\n",
    "        \n",
    "        # Display sample images\n",
    "        for j, idx in enumerate(sample_indices):\n",
    "            plt.subplot(n_clusters, samples_per_cluster, cluster_id * samples_per_cluster + j + 1)\n",
    "            plt.imshow(images[idx].reshape(28, 28), cmap='gray')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # Label the first image in each row\n",
    "            if j == 0:\n",
    "                plt.title(f'Cluster {cluster_id}', fontsize=10)\n",
    "    \n",
    "    plt.suptitle(\"Samples from each cluster\", y=0.95, fontsize=16)\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# 5. Evaluate consistency across multiple runs and identify representative digits\n",
    "def evaluate_cluster_stability(digits, labels, n_clusters):\n",
    "    \"\"\"\n",
    "    Analyze clusters to find their likely digit identities and evaluate consistency\n",
    "    \"\"\"\n",
    "    # Find the centroid images for each cluster\n",
    "    centroids = []\n",
    "    for i in range(n_clusters):\n",
    "        cluster_indices = np.where(labels == i)[0]\n",
    "        if len(cluster_indices) > 0:\n",
    "            cluster_samples = digits[cluster_indices].reshape(len(cluster_indices), -1)\n",
    "            centroid = np.mean(cluster_samples, axis=0)\n",
    "            # Find the image closest to the centroid\n",
    "            distances = np.linalg.norm(cluster_samples - centroid, axis=1)\n",
    "            representative_idx = cluster_indices[np.argmin(distances)]\n",
    "            centroids.append((i, representative_idx))\n",
    "    \n",
    "    # Display centroids with higher resolution\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    for i, (cluster_id, idx) in enumerate(centroids):\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        plt.imshow(digits[idx].reshape(28, 28), cmap='gray', interpolation='none')\n",
    "        plt.title(f\"Cluster {cluster_id}\")\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(\"Representative examples from each cluster\", y=1.02, fontsize=16)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Please manually assign digit labels to each cluster based on the representative images.\")\n",
    "    print(\"Example: cluster_to_digit = {0:3, 1:4, 2:1, ...}\")\n",
    "    \n",
    "    return centroids\n",
    "\n",
    "# Main execution\n",
    "# 1. Generate improved embeddings\n",
    "deep_embeddings, deep_model = create_deep_cnn_embeddings(X)\n",
    "\n",
    "# 2. Perform improved clustering\n",
    "cluster_labels, cluster_model, n_clusters = improved_clustering(deep_embeddings)\n",
    "\n",
    "# 3. Visualize results\n",
    "tsne_embedding = visualize_clusters(deep_embeddings, cluster_labels, n_clusters)\n",
    "\n",
    "# 4. Evaluate and identify clusters\n",
    "centroids = evaluate_cluster_stability(digits, cluster_labels, n_clusters)\n",
    "\n",
    "# 5. Save results\n",
    "np.save('improved_digit_labels.npy', cluster_labels)\n",
    "np.savez('improved_clustering_results.npz', \n",
    "         labels=cluster_labels, \n",
    "         embeddings=deep_embeddings,\n",
    "         tsne=tsne_embedding)\n",
    "\n",
    "print(\"Improved clustering complete! The new labels have been saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
